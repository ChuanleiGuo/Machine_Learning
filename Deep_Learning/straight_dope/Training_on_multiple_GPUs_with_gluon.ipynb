{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd, gluon, autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = gluon.nn.Sequential(prefix=\"cnn_\")\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Conv2D(channels=20, kernel_size=3, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    net.add(gluon.nn.Conv2D(channels=50, kernel_size=5, activation='relu'))\n",
    "    net.add(gluon.nn.MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "    net.add(gluon.nn.Flatten())\n",
    "    net.add(gluon.nn.Dense(128, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(10))\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2D(20, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (1): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
       "  (2): Conv2D(50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (3): MaxPool2D(size=(2, 2), stride=(2, 2), padding=(0, 0), ceil_mode=False)\n",
       "  (4): Flatten\n",
       "  (5): Dense(128, Activation(relu))\n",
       "  (6): Dense(10, linear)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn_ (\n",
       "  Parameter cnn_conv0_weight (shape=(20, 1, 3, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter cnn_conv0_bias (shape=(20,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter cnn_conv1_weight (shape=(50, 20, 5, 5), dtype=<class 'numpy.float32'>)\n",
       "  Parameter cnn_conv1_bias (shape=(50,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter cnn_dense0_weight (shape=(128, 800), dtype=<class 'numpy.float32'>)\n",
       "  Parameter cnn_dense0_bias (shape=(128,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter cnn_dense1_weight (shape=(10, 128), dtype=<class 'numpy.float32'>)\n",
       "  Parameter cnn_dense1_bias (shape=(10,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GPU_COUNT = 2 # increase if you have more\n",
    "ctx = [mx.gpu(i) for i in range(GPU_COUNT)]\n",
    "net.collect_params().initialize(ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[-0.01876061 -0.02165035 -0.01293944  0.03837406 -0.00821797 -0.0091153\n",
      "   0.00416799 -0.00729157 -0.0023271  -0.00155548]\n",
      " [ 0.00441475 -0.01953595 -0.00128483  0.02768222  0.01389614 -0.01320441\n",
      "  -0.01166505 -0.00637777  0.01354249 -0.00611765]]\n",
      "<NDArray 2x10 @gpu(0)>\n",
      "\n",
      "[[ -6.78736810e-03  -8.86893645e-03  -1.04004759e-02   1.72976386e-02\n",
      "    2.26115324e-02  -6.36630971e-03  -1.54974945e-02  -1.22633735e-02\n",
      "    1.19591532e-02  -6.60009682e-05]\n",
      " [ -1.17358584e-02  -2.16879621e-02   1.71219651e-03   2.49827579e-02\n",
      "    1.16810845e-02  -9.52543132e-03  -1.03610354e-02   5.08510135e-03\n",
      "    7.06663402e-03  -9.25292633e-03]]\n",
      "<NDArray 2x10 @gpu(1)>\n"
     ]
    }
   ],
   "source": [
    "from mxnet.test_utils import get_mnist\n",
    "mnist = get_mnist()\n",
    "batch = mnist['train_data'][0:GPU_COUNT*2, :]\n",
    "data = gluon.utils.split_and_load(batch, ctx)\n",
    "print(net(data[0]))\n",
    "print(net(data[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== channel 0 of the first conv on gpu(0) ===\n",
      "[[[ 0.04118239  0.05352169 -0.04762455]\n",
      "  [ 0.06035256 -0.01528978  0.04946674]\n",
      "  [ 0.06110793 -0.00081179  0.02191102]]]\n",
      "<NDArray 1x3x3 @gpu(0)>\n",
      "=== channel 0 of the first conv on gpu(1) ===\n",
      "[[[ 0.04118239  0.05352169 -0.04762455]\n",
      "  [ 0.06035256 -0.01528978  0.04946674]\n",
      "  [ 0.06110793 -0.00081179  0.02191102]]]\n",
      "<NDArray 1x3x3 @gpu(1)>\n"
     ]
    }
   ],
   "source": [
    "weight = net.collect_params()['cnn_conv0_weight']\n",
    "\n",
    "for c in ctx:\n",
    "    print('=== channel 0 of the first conv on {} ==={}'.format(\n",
    "        c, weight.data(ctx=c)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== grad of channel 0 of the first conv2d on gpu(0) ===\n",
      "[[[-0.02078936 -0.00562427  0.01711006]\n",
      "  [ 0.01138538  0.0280002   0.04094724]\n",
      "  [ 0.00993335  0.01218192  0.02122577]]]\n",
      "<NDArray 1x3x3 @gpu(0)>\n",
      "=== grad of channel 0 of the first conv2d on gpu(1) ===\n",
      "[[[-0.02543038 -0.0278994  -0.00302116]\n",
      "  [-0.04816785 -0.03347274 -0.00403482]\n",
      "  [-0.03178394 -0.01254032  0.00855637]]]\n",
      "<NDArray 1x3x3 @gpu(1)>\n"
     ]
    }
   ],
   "source": [
    "def forward_backward(net, data, label):\n",
    "    with autograd.record():\n",
    "        losses = [loss(net(X), Y) for X, Y in zip(data, label)]\n",
    "    for l in losses:\n",
    "        l.backward()\n",
    "\n",
    "label = gluon.utils.split_and_load(mnist['train_label'][0:4], ctx)\n",
    "forward_backward(net, data, label)\n",
    "for c in ctx:\n",
    "    print('=== grad of channel 0 of the first conv2d on {} ==={}'.format(\n",
    "        c, weight.grad(ctx=c)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on [gpu(0)]\n",
      "Batch size is 64\n",
      "Epoch 0, training time = 2.9 sec\n",
      "         validation accuracy = 0.9701\n",
      "Epoch 1, training time = 2.6 sec\n",
      "         validation accuracy = 0.9826\n",
      "Epoch 2, training time = 2.6 sec\n",
      "         validation accuracy = 0.9852\n",
      "Epoch 3, training time = 2.6 sec\n",
      "         validation accuracy = 0.9862\n",
      "Epoch 4, training time = 2.7 sec\n",
      "         validation accuracy = 0.9867\n",
      "Running on [gpu(0), gpu(1)]\n",
      "Batch size is 128\n",
      "Epoch 0, training time = 2.8 sec\n",
      "         validation accuracy = 0.9493\n",
      "Epoch 1, training time = 2.6 sec\n",
      "         validation accuracy = 0.9714\n",
      "Epoch 2, training time = 2.4 sec\n",
      "         validation accuracy = 0.9788\n",
      "Epoch 3, training time = 2.5 sec\n",
      "         validation accuracy = 0.9830\n",
      "Epoch 4, training time = 2.3 sec\n",
      "         validation accuracy = 0.9852\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from mxnet.io import NDArrayIter\n",
    "from time import time\n",
    "\n",
    "def train_batch(batch, ctx, net, trainer):\n",
    "    # split the data batch and load them on GPUs\n",
    "    data = gluon.utils.split_and_load(batch.data[0], ctx)\n",
    "    label = gluon.utils.split_and_load(batch.label[0], ctx)\n",
    "    # compute gradient\n",
    "    forward_backward(net, data, label)\n",
    "    # update parameters\n",
    "    trainer.step(batch.data[0].shape[0])\n",
    "\n",
    "def valid_batch(batch, ctx, net):\n",
    "    data = batch.data[0].as_in_context(ctx[0])\n",
    "    pred = nd.argmax(net(data), axis=1)\n",
    "    return nd.sum(pred == batch.label[0].as_in_context(ctx[0])).asscalar()\n",
    "\n",
    "def run(num_gpus, batch_size, lr):\n",
    "    # the list of GPUs will be used\n",
    "    ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "    print('Running on {}'.format(ctx))\n",
    "\n",
    "    # data iterator\n",
    "    mnist = get_mnist()\n",
    "    train_data = NDArrayIter(mnist[\"train_data\"], mnist[\"train_label\"], batch_size)\n",
    "    valid_data = NDArrayIter(mnist[\"test_data\"], mnist[\"test_label\"], batch_size)\n",
    "    print('Batch size is {}'.format(batch_size))\n",
    "\n",
    "    net.collect_params().initialize(force_reinit=True, ctx=ctx)\n",
    "    trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "    for epoch in range(5):\n",
    "        # train\n",
    "        start = time()\n",
    "        train_data.reset()\n",
    "        for batch in train_data:\n",
    "            train_batch(batch, ctx, net, trainer)\n",
    "        nd.waitall()  # wait until all computations are finished to benchmark the time\n",
    "        print('Epoch %d, training time = %.1f sec'%(epoch, time()-start))\n",
    "\n",
    "        # validating\n",
    "        valid_data.reset()\n",
    "        correct, num = 0.0, 0.0\n",
    "        for batch in valid_data:\n",
    "            correct += valid_batch(batch, ctx, net)\n",
    "            num += batch.data[0].shape[0]\n",
    "        print('         validation accuracy = %.4f'%(correct/num))\n",
    "\n",
    "run(1, 64, .3)\n",
    "run(GPU_COUNT, 64*GPU_COUNT, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
