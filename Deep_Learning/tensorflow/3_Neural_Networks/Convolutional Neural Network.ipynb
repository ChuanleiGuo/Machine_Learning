{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Tensorflow 实现 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_iters = 200000\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# network parameters\n",
    "\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "dropout = 0.75  # probability to keep units\n",
    "\n",
    "# input \n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_input])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\"SAME\")\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    # maxpool2d wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "    \n",
    "    # convolution layer\n",
    "    conv1 = conv2d(x, weights[\"wc1\"], biases[\"bc1\"])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    conv2 = conv2d(conv1, weights[\"wc2\"], biases[\"bc2\"])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    fc1 = tf.reshape(conv2, [-1, weights[\"wd1\"].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights[\"wd1\"]), biases[\"bd1\"])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    out = tf.add(tf.matmul(fc1, weights[\"out\"]), biases[\"out\"])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = {\n",
    "    \"wc1\": tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    \"wc2\": tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    \"wd1\": tf.Variable(tf.random_normal([7 * 7 * 64, 1024])),\n",
    "    \"out\": tf.Variable(tf.random_normal([1024, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"bc1\": tf.Variable(tf.random_normal([32])),\n",
    "    \"bc2\": tf.Variable(tf.random_normal([64])),\n",
    "    \"bd1\": tf.Variable(tf.random_normal([1024])),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1280, Minibatch Loss=20948.316406, Training Accuracy=0.17969\n",
      "Iter: 2560, Minibatch Loss=10720.512695, Training Accuracy=0.48438\n",
      "Iter: 3840, Minibatch Loss=7876.099121, Training Accuracy=0.60156\n",
      "Iter: 5120, Minibatch Loss=4711.554688, Training Accuracy=0.74219\n",
      "Iter: 6400, Minibatch Loss=4238.761230, Training Accuracy=0.74219\n",
      "Iter: 7680, Minibatch Loss=5195.278320, Training Accuracy=0.75781\n",
      "Iter: 8960, Minibatch Loss=2770.641113, Training Accuracy=0.79688\n",
      "Iter: 10240, Minibatch Loss=2942.683105, Training Accuracy=0.83594\n",
      "Iter: 11520, Minibatch Loss=1038.053101, Training Accuracy=0.91406\n",
      "Iter: 12800, Minibatch Loss=3103.335693, Training Accuracy=0.83594\n",
      "Iter: 14080, Minibatch Loss=911.368713, Training Accuracy=0.90625\n",
      "Iter: 15360, Minibatch Loss=1341.486694, Training Accuracy=0.90625\n",
      "Iter: 16640, Minibatch Loss=1867.321045, Training Accuracy=0.90625\n",
      "Iter: 17920, Minibatch Loss=925.473328, Training Accuracy=0.93750\n",
      "Iter: 19200, Minibatch Loss=1213.639893, Training Accuracy=0.91406\n",
      "Iter: 20480, Minibatch Loss=322.417267, Training Accuracy=0.96094\n",
      "Iter: 21760, Minibatch Loss=2921.343994, Training Accuracy=0.85938\n",
      "Iter: 23040, Minibatch Loss=859.901978, Training Accuracy=0.94531\n",
      "Iter: 24320, Minibatch Loss=1005.092773, Training Accuracy=0.87500\n",
      "Iter: 25600, Minibatch Loss=686.689697, Training Accuracy=0.92969\n",
      "Iter: 26880, Minibatch Loss=853.292480, Training Accuracy=0.93750\n",
      "Iter: 28160, Minibatch Loss=909.201782, Training Accuracy=0.91406\n",
      "Iter: 29440, Minibatch Loss=1718.315918, Training Accuracy=0.92969\n",
      "Iter: 30720, Minibatch Loss=974.484009, Training Accuracy=0.91406\n",
      "Iter: 32000, Minibatch Loss=854.971924, Training Accuracy=0.94531\n",
      "Iter: 33280, Minibatch Loss=481.281311, Training Accuracy=0.93750\n",
      "Iter: 34560, Minibatch Loss=233.780960, Training Accuracy=0.96875\n",
      "Iter: 35840, Minibatch Loss=465.155701, Training Accuracy=0.95312\n",
      "Iter: 37120, Minibatch Loss=1140.844604, Training Accuracy=0.91406\n",
      "Iter: 38400, Minibatch Loss=217.609009, Training Accuracy=0.96875\n",
      "Iter: 39680, Minibatch Loss=152.395859, Training Accuracy=0.96875\n",
      "Iter: 40960, Minibatch Loss=1713.716431, Training Accuracy=0.89844\n",
      "Iter: 42240, Minibatch Loss=386.753204, Training Accuracy=0.92188\n",
      "Iter: 43520, Minibatch Loss=353.219788, Training Accuracy=0.98438\n",
      "Iter: 44800, Minibatch Loss=302.309265, Training Accuracy=0.96875\n",
      "Iter: 46080, Minibatch Loss=115.795692, Training Accuracy=0.96875\n",
      "Iter: 47360, Minibatch Loss=989.786072, Training Accuracy=0.92969\n",
      "Iter: 48640, Minibatch Loss=1037.396362, Training Accuracy=0.94531\n",
      "Iter: 49920, Minibatch Loss=342.647797, Training Accuracy=0.94531\n",
      "Iter: 51200, Minibatch Loss=231.274521, Training Accuracy=0.96094\n",
      "Iter: 52480, Minibatch Loss=443.910889, Training Accuracy=0.94531\n",
      "Iter: 53760, Minibatch Loss=114.588348, Training Accuracy=0.98438\n",
      "Iter: 55040, Minibatch Loss=170.463745, Training Accuracy=0.96875\n",
      "Iter: 56320, Minibatch Loss=426.620117, Training Accuracy=0.96875\n",
      "Iter: 57600, Minibatch Loss=468.671173, Training Accuracy=0.95312\n",
      "Iter: 58880, Minibatch Loss=319.673431, Training Accuracy=0.96875\n",
      "Iter: 60160, Minibatch Loss=270.528778, Training Accuracy=0.95312\n",
      "Iter: 61440, Minibatch Loss=990.672913, Training Accuracy=0.89062\n",
      "Iter: 62720, Minibatch Loss=1250.047363, Training Accuracy=0.92969\n",
      "Iter: 64000, Minibatch Loss=457.850220, Training Accuracy=0.96094\n",
      "Iter: 65280, Minibatch Loss=858.695374, Training Accuracy=0.95312\n",
      "Iter: 66560, Minibatch Loss=494.981750, Training Accuracy=0.94531\n",
      "Iter: 67840, Minibatch Loss=270.955322, Training Accuracy=0.98438\n",
      "Iter: 69120, Minibatch Loss=898.739868, Training Accuracy=0.95312\n",
      "Iter: 70400, Minibatch Loss=293.441803, Training Accuracy=0.96875\n",
      "Iter: 71680, Minibatch Loss=167.291840, Training Accuracy=0.97656\n",
      "Iter: 72960, Minibatch Loss=197.387421, Training Accuracy=0.96875\n",
      "Iter: 74240, Minibatch Loss=271.644989, Training Accuracy=0.97656\n",
      "Iter: 75520, Minibatch Loss=570.904907, Training Accuracy=0.95312\n",
      "Iter: 76800, Minibatch Loss=422.050812, Training Accuracy=0.96094\n",
      "Iter: 78080, Minibatch Loss=646.646729, Training Accuracy=0.95312\n",
      "Iter: 79360, Minibatch Loss=356.506409, Training Accuracy=0.94531\n",
      "Iter: 80640, Minibatch Loss=424.144318, Training Accuracy=0.94531\n",
      "Iter: 81920, Minibatch Loss=163.099655, Training Accuracy=0.97656\n",
      "Iter: 83200, Minibatch Loss=299.201019, Training Accuracy=0.96094\n",
      "Iter: 84480, Minibatch Loss=240.794144, Training Accuracy=0.96875\n",
      "Iter: 85760, Minibatch Loss=274.343231, Training Accuracy=0.97656\n",
      "Iter: 87040, Minibatch Loss=97.379959, Training Accuracy=0.97656\n",
      "Iter: 88320, Minibatch Loss=223.417664, Training Accuracy=0.96875\n",
      "Iter: 89600, Minibatch Loss=281.781982, Training Accuracy=0.97656\n",
      "Iter: 90880, Minibatch Loss=871.025452, Training Accuracy=0.94531\n",
      "Iter: 92160, Minibatch Loss=413.761902, Training Accuracy=0.96094\n",
      "Iter: 93440, Minibatch Loss=547.320251, Training Accuracy=0.95312\n",
      "Iter: 94720, Minibatch Loss=132.375946, Training Accuracy=0.97656\n",
      "Iter: 96000, Minibatch Loss=443.018982, Training Accuracy=0.97656\n",
      "Iter: 97280, Minibatch Loss=151.917542, Training Accuracy=0.95312\n",
      "Iter: 98560, Minibatch Loss=168.163025, Training Accuracy=0.96094\n",
      "Iter: 99840, Minibatch Loss=458.061768, Training Accuracy=0.96094\n",
      "Iter: 101120, Minibatch Loss=266.427979, Training Accuracy=0.96094\n",
      "Iter: 102400, Minibatch Loss=83.345062, Training Accuracy=0.97656\n",
      "Iter: 103680, Minibatch Loss=479.935120, Training Accuracy=0.96094\n",
      "Iter: 104960, Minibatch Loss=442.964386, Training Accuracy=0.95312\n",
      "Iter: 106240, Minibatch Loss=59.664001, Training Accuracy=0.99219\n",
      "Iter: 107520, Minibatch Loss=586.290710, Training Accuracy=0.94531\n",
      "Iter: 108800, Minibatch Loss=355.680359, Training Accuracy=0.95312\n",
      "Iter: 110080, Minibatch Loss=224.268311, Training Accuracy=0.96094\n",
      "Iter: 111360, Minibatch Loss=212.150955, Training Accuracy=0.97656\n",
      "Iter: 112640, Minibatch Loss=150.274902, Training Accuracy=0.96875\n",
      "Iter: 113920, Minibatch Loss=0.000000, Training Accuracy=1.00000\n",
      "Iter: 115200, Minibatch Loss=67.160194, Training Accuracy=0.97656\n",
      "Iter: 116480, Minibatch Loss=52.024570, Training Accuracy=0.98438\n",
      "Iter: 117760, Minibatch Loss=115.037857, Training Accuracy=0.97656\n",
      "Iter: 119040, Minibatch Loss=183.638412, Training Accuracy=0.97656\n",
      "Iter: 120320, Minibatch Loss=74.347725, Training Accuracy=0.98438\n",
      "Iter: 121600, Minibatch Loss=8.834106, Training Accuracy=0.99219\n",
      "Iter: 122880, Minibatch Loss=371.050873, Training Accuracy=0.94531\n",
      "Iter: 124160, Minibatch Loss=118.946831, Training Accuracy=0.96875\n",
      "Iter: 125440, Minibatch Loss=122.841934, Training Accuracy=0.97656\n",
      "Iter: 126720, Minibatch Loss=385.601624, Training Accuracy=0.96875\n",
      "Iter: 128000, Minibatch Loss=127.244736, Training Accuracy=0.98438\n",
      "Iter: 129280, Minibatch Loss=307.746033, Training Accuracy=0.96875\n",
      "Iter: 130560, Minibatch Loss=296.572937, Training Accuracy=0.96875\n",
      "Iter: 131840, Minibatch Loss=12.033134, Training Accuracy=0.99219\n",
      "Iter: 133120, Minibatch Loss=131.387817, Training Accuracy=0.96875\n",
      "Iter: 134400, Minibatch Loss=140.890335, Training Accuracy=0.97656\n",
      "Iter: 135680, Minibatch Loss=193.802505, Training Accuracy=0.98438\n",
      "Iter: 136960, Minibatch Loss=239.102478, Training Accuracy=0.96094\n",
      "Iter: 138240, Minibatch Loss=451.838928, Training Accuracy=0.94531\n",
      "Iter: 139520, Minibatch Loss=242.304260, Training Accuracy=0.96094\n",
      "Iter: 140800, Minibatch Loss=96.842812, Training Accuracy=0.97656\n",
      "Iter: 142080, Minibatch Loss=300.542419, Training Accuracy=0.96875\n",
      "Iter: 143360, Minibatch Loss=60.617867, Training Accuracy=0.98438\n",
      "Iter: 144640, Minibatch Loss=252.813019, Training Accuracy=0.97656\n",
      "Iter: 145920, Minibatch Loss=300.259766, Training Accuracy=0.96875\n",
      "Iter: 147200, Minibatch Loss=174.542786, Training Accuracy=0.97656\n",
      "Iter: 148480, Minibatch Loss=210.501434, Training Accuracy=0.97656\n",
      "Iter: 149760, Minibatch Loss=81.079971, Training Accuracy=0.96875\n",
      "Iter: 151040, Minibatch Loss=246.880157, Training Accuracy=0.96094\n",
      "Iter: 152320, Minibatch Loss=338.885193, Training Accuracy=0.96094\n",
      "Iter: 153600, Minibatch Loss=182.319687, Training Accuracy=0.98438\n",
      "Iter: 154880, Minibatch Loss=0.000000, Training Accuracy=1.00000\n",
      "Iter: 156160, Minibatch Loss=120.444023, Training Accuracy=0.97656\n",
      "Iter: 157440, Minibatch Loss=157.629776, Training Accuracy=0.97656\n",
      "Iter: 158720, Minibatch Loss=31.115721, Training Accuracy=0.96875\n",
      "Iter: 160000, Minibatch Loss=136.234070, Training Accuracy=0.98438\n",
      "Iter: 161280, Minibatch Loss=440.885071, Training Accuracy=0.95312\n",
      "Iter: 162560, Minibatch Loss=253.694885, Training Accuracy=0.96875\n",
      "Iter: 163840, Minibatch Loss=6.060648, Training Accuracy=0.99219\n",
      "Iter: 165120, Minibatch Loss=301.521667, Training Accuracy=0.96875\n",
      "Iter: 166400, Minibatch Loss=59.298485, Training Accuracy=0.97656\n",
      "Iter: 167680, Minibatch Loss=123.890907, Training Accuracy=0.96875\n",
      "Iter: 168960, Minibatch Loss=76.967354, Training Accuracy=0.96875\n",
      "Iter: 170240, Minibatch Loss=323.565308, Training Accuracy=0.95312\n",
      "Iter: 171520, Minibatch Loss=150.107529, Training Accuracy=0.96875\n",
      "Iter: 172800, Minibatch Loss=307.268921, Training Accuracy=0.97656\n",
      "Iter: 174080, Minibatch Loss=70.402786, Training Accuracy=0.98438\n",
      "Iter: 175360, Minibatch Loss=126.383568, Training Accuracy=0.98438\n",
      "Iter: 176640, Minibatch Loss=0.000000, Training Accuracy=1.00000\n",
      "Iter: 177920, Minibatch Loss=211.175552, Training Accuracy=0.96875\n",
      "Iter: 179200, Minibatch Loss=78.329330, Training Accuracy=0.97656\n",
      "Iter: 180480, Minibatch Loss=37.183414, Training Accuracy=0.99219\n",
      "Iter: 181760, Minibatch Loss=164.752563, Training Accuracy=0.96875\n",
      "Iter: 183040, Minibatch Loss=120.933487, Training Accuracy=0.96094\n",
      "Iter: 184320, Minibatch Loss=1.901917, Training Accuracy=0.99219\n",
      "Iter: 185600, Minibatch Loss=75.987244, Training Accuracy=0.96875\n",
      "Iter: 186880, Minibatch Loss=28.072723, Training Accuracy=0.99219\n",
      "Iter: 188160, Minibatch Loss=163.649551, Training Accuracy=0.98438\n",
      "Iter: 189440, Minibatch Loss=178.746368, Training Accuracy=0.96875\n",
      "Iter: 190720, Minibatch Loss=38.953453, Training Accuracy=0.98438\n",
      "Iter: 192000, Minibatch Loss=120.860527, Training Accuracy=0.97656\n",
      "Iter: 193280, Minibatch Loss=140.394043, Training Accuracy=0.96094\n",
      "Iter: 194560, Minibatch Loss=243.381226, Training Accuracy=0.97656\n",
      "Iter: 195840, Minibatch Loss=0.000000, Training Accuracy=1.00000\n",
      "Iter: 197120, Minibatch Loss=70.071365, Training Accuracy=0.97656\n",
      "Iter: 198400, Minibatch Loss=142.624527, Training Accuracy=0.96875\n",
      "Iter: 199680, Minibatch Loss=402.548401, Training Accuracy=0.95312\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.98047\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    step = 1\n",
    "    while step * batch_size < training_iters:\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        \n",
    "        sess.run(optimizer, feed_dict={\n",
    "            x: batch_x,\n",
    "            y: batch_y,\n",
    "            keep_prob: dropout\n",
    "        })\n",
    "        \n",
    "        if step % display_step == 0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.\n",
    "            })\n",
    "            print(\"Iter: {:d}, Minibatch Loss={:.6f}, Training Accuracy={:.5f}\".format(step*batch_size, loss, acc))\n",
    "        step += 1\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Testing Accuracy: {:.5f}\".format(sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:256],\n",
    "        y: mnist.test.labels[:256],\n",
    "        keep_prob: 1.\n",
    "    })))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
