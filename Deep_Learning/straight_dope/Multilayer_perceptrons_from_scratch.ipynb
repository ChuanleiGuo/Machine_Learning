{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /Users/chuan/.mxnet/datasets/mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-images-idx3-ubyte.gz...\n",
      "Downloading /Users/chuan/.mxnet/datasets/mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/train-labels-idx1-ubyte.gz...\n",
      "Downloading /Users/chuan/.mxnet/datasets/mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-images-idx3-ubyte.gz...\n",
      "Downloading /Users/chuan/.mxnet/datasets/mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/mnist/t10k-labels-idx1-ubyte.gz...\n"
     ]
    }
   ],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "batch_size = 64\n",
    "def transform(data, label):\n",
    "    return data.astype(np.float32)/255, label.astype(np.float32)\n",
    "train_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_hidden = 256\n",
    "weight_scale = 0.01\n",
    "\n",
    "W1 = nd.random_normal(shape=(num_inputs, num_hidden), scale=weight_scale, ctx=ctx)\n",
    "b1 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the second hidden layer\n",
    "#######################\n",
    "W2 = nd.random_normal(shape=(num_hidden, num_hidden), scale=weight_scale, ctx=ctx)\n",
    "b2 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the output layer\n",
    "#######################\n",
    "W3 = nd.random_normal(shape=(num_hidden, num_outputs), scale=weight_scale, ctx=ctx)\n",
    "b3 = nd.random_normal(shape=num_outputs, scale=weight_scale, ctx=ctx)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return nd.maximum(X, nd.zeros_like(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    partition = nd.nansum(exp, axis=0, exclude=True).reshape((-1, 1))\n",
    "    return exp / partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_entropy(yhat, y):\n",
    "    return - nd.nansum(y * nd.log(yhat), axis=0, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax_cross_entropy(yhat_linear, y):\n",
    "    return - nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    #######################\n",
    "    #  Compute the first hidden layer\n",
    "    #######################\n",
    "    h1_linear = nd.dot(X, W1) + b1\n",
    "    h1 = relu(h1_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the second hidden layer\n",
    "    #######################\n",
    "    h2_linear = nd.dot(h1, W2) + b2\n",
    "    h2 = relu(h2_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the output layer.\n",
    "    #  We will omit the softmax function here\n",
    "    #  because it will be applied\n",
    "    #  in the softmax_cross_entropy loss\n",
    "    #######################\n",
    "    yhat_linear = nd.dot(h2, W3) + b3\n",
    "    return yhat_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.497096817613, Train_acc 0.878617, Test_acc 0.878\n",
      "Epoch 1. Loss: 0.295615466408, Train_acc 0.9244, Test_acc 0.9229\n",
      "Epoch 2. Loss: 0.196498506766, Train_acc 0.946417, Test_acc 0.9454\n",
      "Epoch 3. Loss: 0.145237323231, Train_acc 0.9587, Test_acc 0.9586\n",
      "Epoch 4. Loss: 0.123926521657, Train_acc 0.969867, Test_acc 0.9664\n",
      "Epoch 5. Loss: 0.109008631587, Train_acc 0.973967, Test_acc 0.9677\n",
      "Epoch 6. Loss: 0.0873471584111, Train_acc 0.978683, Test_acc 0.9718\n",
      "Epoch 7. Loss: 0.0731665571321, Train_acc 0.98255, Test_acc 0.9734\n",
      "Epoch 8. Loss: 0.0598165683626, Train_acc 0.984017, Test_acc 0.9735\n",
      "Epoch 9. Loss: 0.0578878028235, Train_acc 0.986133, Test_acc 0.9747\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "learning_rate = .001\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "\n",
    "        ##########################\n",
    "        #  Keep a moving average of the losses\n",
    "        ##########################\n",
    "        curr_loss = nd.mean(loss).asscalar()\n",
    "        moving_loss = (curr_loss if ((i == 0) and (e == 0))\n",
    "                       else (1 - smoothing_constant) * moving_loss + (smoothing_constant) * curr_loss)\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n",
    "          (e, moving_loss, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
